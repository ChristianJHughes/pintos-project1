
CIS 520 - Programming Project #1


---- GROUP ----

>> Fill in the names and email addresses of your group members.

Matt Hixon <mhixon@k-state.edu>
Christian Hughes <cjhughes255@k-state.edu>
Katie Kristiansen <kkristia@ksu.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for
>> the TA, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation,
>> course text, lecture notes, and course staff.

https://github.com/Hindol/pintos - Inspiration for portions of list sorting function and interrupt handler.


                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* thread.h */
ADDED TO struct thread:
  struct semaphore sema; - A semaphore that can be manipulated for putting the thread to sleep & waking it up.
  int64_t sleep_duration; - How long the thread must sleep, expressed as ticks since the OS Booted Up.
  struct list_elem timer_sleep_elem; - A list element for maintaining a list of sleeping threads in timer.c.

/* timer.c */
GLOBAL VARIABLE:
  static struct list sleeping_threads; - An ordered list to keep track of threads that are asleep.
  static struct lock sleeping_threads_list_lock; - Provides a locking mechanism for the sleeping_threads list.


---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to your timer_sleep(),
>> including the effects of the timer interrupt handler.

We begin by assigning each thread a sleep duration time, and a semaphore initialized to 0. We then add that thread to a list of sleeping threads, and decrement the its semaphore (which puts the thread to sleep). The interrupt handler checks the list of sleeping threads to see if any threads are qualified to wake up (and wakes up all qualifying threads).

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

The list of sleeping threads is kept sorted. The interrupt handler will always begin checking the threads at the beginning of the list, which are those with the shortest sleep duration. If a thread is found that is not ready to wake up, the rest of threads are not checked (sleep duration increases throughout the list).


---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

The only operation in timer_sleep() capable of generating a race condition is the call to list_insert_ordered(). We put a lock around this function to ensure that only one thread is modifying the list at a time.


>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

The only area that a race condition could occur is in between adding a thread to the sleeping_threads list, and decrementing that threads semaphore. Because each thread is added to the list with its sleep_duration time, the timer_interrupt will only remove that thread from the list if is appropriately ready to wake-up (and its semaphore will correctly be restored to a value of 0). Race conditions are therefore eliminated. There is also a lock in timer_interrupt() that ensures only one thread pops from the list at a time.


---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> other designs that you considered?

We didn't want to create a design that required constantly disabling interrupts -- we wanted to maintain preemption to the greatest extent possible. Our use of per-thread semaphores cleanly manages putting threads to sleep and waking them back up. We also maintain a sorted list to maximize the efficiency of the interrupt handler when determining which (if any) threads to wake-up. We used as many built in data-structures as possible to manage synchronization and thread state.


             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* thread.h */
struct list donated_priorities;   - List of priorities that have been donated to the thread.
struct list priority_recipients;  - List of threads that the thread has donated to.
struct list_elem pri_elem;        - List element for keeping track of donated priorities (in thread form - for donated_priorities).
struct list_elem recp_elem;       - A list element for keeping track of this thread in a priority_recipients list.


>> B2: Explain the data structure used to track priority donation.

We use an ordered linked list to keep track of who the thread has received a
priority donation from as well as an additional linked list to keep track of who
the thread has received a priority donation from the thread.

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

When a new thread attempts to acquire a lock, semaphore, or condition variable,
we do a priority comparison to determine if the new thread has a higher priority
than the thread currently holding the lock. If it does have a hire priority, the
current thread is forced to yield and allow the higher priority thread access
while going back on the ready list to wait for the lock, semaphore, or condition
variable to become available again.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

When a new thread tries to acquire a lock, it first checks to see if the lock is
being held by another thread. If the lock is unavailable, the new thread will then
check to see if it has a higher priority than the thread currently holding the lock.
If it does have a higher priority, the new thread will donate it's priority to the
thread holding the lock as well as too anyone that the thread is waiting on.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

When a thread tries to release a lock, the thread checks to see if it has received
a priority donation from any other threads. If it has received a priority donation
it removes that donation from it's list of priority donations and the higher priority
thread removes it from it's list of recipients. The thread then releases the lock so
the highest priority thread can now grab it.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

A potential race occurs in thread_set_priority() when a thread would attempt to
grab it's highest donated priority from the front of the list. A race could occur
here if it were to receive or lose a priority donation while attempting to access
the front of the list. To avoid this possible race condition, we disable interrupts
before accessing the list and turn them back on afterwards.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We maintained all function asserts, and strove to work within the framework of the existing Pintos source code to the greatest extent possible. All of the lists within our implementation are kept in sorted order based on priority, which keeps us from having to constantly search them for the thread with the highest priority. We do not disable interrupts except for when absolutely necessary. The thread struct stores lists of which threads it has donated priority to, and which threads have donated priority to it. This allows us to quickly assess relevant priority when scheduling around a held lock. We considered adding more fields to the thread struct (in order to store other occasionally used values), but instead elected to store only the most essential values.


              ADVANCED SCHEDULER [EXTRA CREDIT]
              =================================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?
